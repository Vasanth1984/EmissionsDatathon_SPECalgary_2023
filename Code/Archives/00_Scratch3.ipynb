{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8029ece-241b-4af0-9232-2f47ae59a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d918eed5-e2d5-448f-88cc-2cc786a5ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdaadc83-7a74-4424-8c7b-2ae92ec203fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train = Path('C:/Users/vasan/OneDrive/EmissionsDatathon/Dataset/Data/Train')\n",
    "\n",
    "dir_name = r'C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Zeroing Methane Emissions - Dataset'\n",
    "filename_suffix = 'csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "470230c4-8540-4403-b122-b63fa5e84d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = pd.Series(list(image_train.glob(r'**/*.png')), name='Filepath').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a86136-0d38-421e-8d78-7a49dc6dae74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...\n",
       "1    C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...\n",
       "2    C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...\n",
       "3    C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...\n",
       "4    C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...\n",
       "Name: Filepath, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepaths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "779d9675-8192-4a6c-802f-73d04ee925c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filepaths = filepaths.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64eaea5d-a5f8-4a55-b863-b2d6bc9765b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3762</th>\n",
       "      <td>C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3763 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Filepath\n",
       "0     C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...\n",
       "1     C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...\n",
       "2     C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...\n",
       "3     C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...\n",
       "4     C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...\n",
       "...                                                 ...\n",
       "3758  C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...\n",
       "3759  C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...\n",
       "3760  C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...\n",
       "3761  C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...\n",
       "3762  C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...\n",
       "\n",
       "[3763 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "768069f6-e19f-4642-8a91-d7a85f91ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = os.listdir(image_train)\n",
    "df_filepaths['Name'] = pd.DataFrame (res, columns = ['FileName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "480462ed-8429-41e3-a970-a00b1e818853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filepaths['candidate_id'] = [x.split('_')[-0] for x in df_filepaths['Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "748dc9ed-78ae-4207-a218-a1284aa86b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filepaths.to_excel(\"output.xlsx\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fcddee2-0f02-4b0f-9ea7-9f8e38ae1b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source_id</th>\n",
       "      <th>plume_lat</th>\n",
       "      <th>plume_lon</th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>qplume</th>\n",
       "      <th>sigma_qplume</th>\n",
       "      <th>active_flair_detected</th>\n",
       "      <th>inactive_flair_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>P00001</td>\n",
       "      <td>32.212063</td>\n",
       "      <td>-103.697076</td>\n",
       "      <td>ang20190922t192642-2</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>19:26:42</td>\n",
       "      <td>2579.528100</td>\n",
       "      <td>902.732655</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>P00002</td>\n",
       "      <td>32.200072</td>\n",
       "      <td>-103.673301</td>\n",
       "      <td>ang20190922t192642-4</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>19:26:42</td>\n",
       "      <td>420.725207</td>\n",
       "      <td>147.155782</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>P00003</td>\n",
       "      <td>32.116008</td>\n",
       "      <td>-103.626345</td>\n",
       "      <td>ang20190922t192642-5</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>19:26:42</td>\n",
       "      <td>1051.909600</td>\n",
       "      <td>339.267587</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>P00004</td>\n",
       "      <td>32.322594</td>\n",
       "      <td>-103.816072</td>\n",
       "      <td>ang20190922t194340-1</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>19:43:40</td>\n",
       "      <td>1736.644250</td>\n",
       "      <td>1035.427670</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>P00005</td>\n",
       "      <td>32.284083</td>\n",
       "      <td>-103.793989</td>\n",
       "      <td>ang20190922t194340-2</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>19:43:40</td>\n",
       "      <td>870.605019</td>\n",
       "      <td>435.968147</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 source_id  plume_lat   plume_lon          candidate_id  \\\n",
       "0           0    P00001  32.212063 -103.697076  ang20190922t192642-2   \n",
       "1           1    P00002  32.200072 -103.673301  ang20190922t192642-4   \n",
       "2           2    P00003  32.116008 -103.626345  ang20190922t192642-5   \n",
       "3           3    P00004  32.322594 -103.816072  ang20190922t194340-1   \n",
       "4           4    P00005  32.284083 -103.793989  ang20190922t194340-2   \n",
       "\n",
       "         date      time       qplume  sigma_qplume  active_flair_detected  \\\n",
       "0  2019-09-22  19:26:42  2579.528100    902.732655                  False   \n",
       "1  2019-09-22  19:26:42   420.725207    147.155782                  False   \n",
       "2  2019-09-22  19:26:42  1051.909600    339.267587                  False   \n",
       "3  2019-09-22  19:43:40  1736.644250   1035.427670                  False   \n",
       "4  2019-09-22  19:43:40   870.605019    435.968147                  False   \n",
       "\n",
       "   inactive_flair_detected  \n",
       "0                    False  \n",
       "1                    False  \n",
       "2                    False  \n",
       "3                    False  \n",
       "4                    False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skiprows = 0\n",
    "#Means read in the ',' as thousand seperator. Also drops all columns which are unnamed.\n",
    "df = pd.read_csv(\"permian_plume_list_2019 Jeremy Zhao.csv\", thousands=',', skiprows = skiprows)\n",
    "#df = df.loc[:, ~df.columns.str.contains('^Unnamed')] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51818166-41f2-4186-9587-26d88e3d26c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3067, 11)\n",
      "(3763, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df_filepaths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "854e5654-724e-4407-b4b4-cf4eff040509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.merge(df_filepaths, df, on='candidate_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b3f595b-3e6e-479e-af77-097cb35199af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3067, 13)\n"
     ]
    }
   ],
   "source": [
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea7352e8-3919-496b-940b-0edbc579cce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Name</th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source_id</th>\n",
       "      <th>plume_lat</th>\n",
       "      <th>plume_lon</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>qplume</th>\n",
       "      <th>sigma_qplume</th>\n",
       "      <th>active_flair_detected</th>\n",
       "      <th>inactive_flair_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...</td>\n",
       "      <td>ang20190922t192642-2_r4578_c217-plume.png</td>\n",
       "      <td>ang20190922t192642-2</td>\n",
       "      <td>0</td>\n",
       "      <td>P00001</td>\n",
       "      <td>32.212063</td>\n",
       "      <td>-103.697076</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>19:26:42</td>\n",
       "      <td>2579.528100</td>\n",
       "      <td>902.732655</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...</td>\n",
       "      <td>ang20190922t192642-4_r4928_c373-plume.png</td>\n",
       "      <td>ang20190922t192642-4</td>\n",
       "      <td>1</td>\n",
       "      <td>P00002</td>\n",
       "      <td>32.200072</td>\n",
       "      <td>-103.673301</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>19:26:42</td>\n",
       "      <td>420.725207</td>\n",
       "      <td>147.155782</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...</td>\n",
       "      <td>ang20190922t192642-5_r6423_c113-plume.png</td>\n",
       "      <td>ang20190922t192642-5</td>\n",
       "      <td>2</td>\n",
       "      <td>P00003</td>\n",
       "      <td>32.116008</td>\n",
       "      <td>-103.626345</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>19:26:42</td>\n",
       "      <td>1051.909600</td>\n",
       "      <td>339.267587</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...</td>\n",
       "      <td>ang20190922t192642-A_r3270_c384-plume.png</td>\n",
       "      <td>ang20190922t192642-A</td>\n",
       "      <td>759</td>\n",
       "      <td>P00156</td>\n",
       "      <td>32.283447</td>\n",
       "      <td>-103.741815</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>19:26:42</td>\n",
       "      <td>296.676732</td>\n",
       "      <td>98.755811</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...</td>\n",
       "      <td>ang20190922t192642-B_r4034_c360-plume.png</td>\n",
       "      <td>ang20190922t192642-B</td>\n",
       "      <td>760</td>\n",
       "      <td>P00119</td>\n",
       "      <td>32.244361</td>\n",
       "      <td>-103.711379</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>19:26:42</td>\n",
       "      <td>640.968143</td>\n",
       "      <td>190.138173</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filepath  \\\n",
       "0  C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...   \n",
       "1  C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...   \n",
       "2  C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...   \n",
       "3  C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...   \n",
       "4  C:\\Users\\vasan\\OneDrive\\EmissionsDatathon\\Data...   \n",
       "\n",
       "                                        Name          candidate_id  \\\n",
       "0  ang20190922t192642-2_r4578_c217-plume.png  ang20190922t192642-2   \n",
       "1  ang20190922t192642-4_r4928_c373-plume.png  ang20190922t192642-4   \n",
       "2  ang20190922t192642-5_r6423_c113-plume.png  ang20190922t192642-5   \n",
       "3  ang20190922t192642-A_r3270_c384-plume.png  ang20190922t192642-A   \n",
       "4  ang20190922t192642-B_r4034_c360-plume.png  ang20190922t192642-B   \n",
       "\n",
       "   Unnamed: 0 source_id  plume_lat   plume_lon        date      time  \\\n",
       "0           0    P00001  32.212063 -103.697076  2019-09-22  19:26:42   \n",
       "1           1    P00002  32.200072 -103.673301  2019-09-22  19:26:42   \n",
       "2           2    P00003  32.116008 -103.626345  2019-09-22  19:26:42   \n",
       "3         759    P00156  32.283447 -103.741815  2019-09-22  19:26:42   \n",
       "4         760    P00119  32.244361 -103.711379  2019-09-22  19:26:42   \n",
       "\n",
       "        qplume  sigma_qplume  active_flair_detected  inactive_flair_detected  \n",
       "0  2579.528100    902.732655                  False                    False  \n",
       "1   420.725207    147.155782                  False                    False  \n",
       "2  1051.909600    339.267587                  False                    False  \n",
       "3   296.676732     98.755811                  False                    False  \n",
       "4   640.968143    190.138173                  False                    False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0cfbda1-d71b-4965-a2de-94ceccdd37c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3067"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['candidate_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0882694-0ab6-4f8a-8180-7e8eb477cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_zscore(data, threshold=3):\n",
    "    z_scores = np.abs((data - np.mean(data)) / np.std(data))\n",
    "    num_outliers = np.sum(z_scores > threshold)\n",
    "    return num_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dca84f8-8ccb-4b9d-906b-150227f27210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_outliers_zscore(df2['qplume'], threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b244d51-a31a-4614-b163-05cae73a633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outliers_zscore(data, threshold=3):\n",
    "    z_scores = np.abs((data - np.mean(data)) / np.std(data))\n",
    "    return data[z_scores <= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f253ecf2-2b61-4a18-801b-b7e0d2f925c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_excel(\"output2.xlsx\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "047c9fea-3c27-44ca-9f4e-d9ad071f5304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2579.528100\n",
       "1        420.725207\n",
       "2       1051.909600\n",
       "3        296.676732\n",
       "4        640.968143\n",
       "           ...     \n",
       "3062     244.219726\n",
       "3063     185.375804\n",
       "3064     237.801830\n",
       "3065     282.037503\n",
       "3066     174.266195\n",
       "Name: qplume, Length: 3018, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_outliers_zscore(df2.qplume, threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7eb3c876-5814-430a-a97e-32296db9d97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3067, 13)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96fa3d08-62a1-45cb-8056-00f168c8abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df2, train_size=0.7, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ca59bb8-c36d-4155-9940-9b56241fbe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9828c6ab-d229-4dd2-b954-0ec5b0ed7b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb55a4e4-0ed9-42ad-a838-b29973659052",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30aa37b-93d3-4330-9d48-69a66609ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421d2e4-a362-4c80-a16b-06a5bc16583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "# https://www.kaggle.com/code/gcdatkin/age-prediction-from-images-cnn-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27841799-4208-4c9d-a04e-a6426767e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='qplume',\n",
    "    target_size=(217, 217),\n",
    "    color_mode='rgba',\n",
    "    class_mode='raw',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093924c5-1239-4cb6-8370-89e59d3eb8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f135105-54cc-4683-ad84-2cbcf8f1de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='qplume',\n",
    "    target_size=(217, 217),\n",
    "    color_mode='rgba',\n",
    "    class_mode='raw',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadc4937-83b8-4240-aedd-fae37eaa69c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='qplume',\n",
    "    target_size=(217, 217),\n",
    "    color_mode='rgba',\n",
    "    class_mode='raw',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625f69e-aa5c-4400-a4f9-58fa9e9efcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(217, 217, 4))\n",
    "x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data=val_images,\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd0986e-2c43-490e-8a2b-862b63bab0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ages = np.squeeze(model.predict(test_images))\n",
    "true_ages = test_images.labels\n",
    "\n",
    "rmse = np.sqrt(model.evaluate(test_images, verbose=0))\n",
    "print(\"     Test RMSE: {:.5f}\".format(rmse))\n",
    "\n",
    "r2 = r2_score(true_ages, predicted_ages)\n",
    "print(\"Test R^2 Score: {:.5f}\".format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a130f1cc-effa-4f94-99d6-eb1d4309fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rmse = np.sqrt(np.sum((true_ages - np.mean(true_ages))**2) / len(true_ages))\n",
    "print(\"Null/Baseline Model Test RMSE: {:.5f}\".format(null_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef5996-55a5-45a3-a9dc-ed459ee8d4ae",
   "metadata": {},
   "source": [
    "# 2nd Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be887944-81c5-4337-87f2-177336761534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_processing(fil):\n",
    "#Open image and import it as a numpy array\n",
    "    with open(fil, 'rb') as f:\n",
    "        im1 = f.read()\n",
    "    im1_data = np.frombuffer(im1, dtype='uint8')\n",
    "#Read the numpy arrays as color images in OpenCV\n",
    "    image_bgr2 = cv2.imdecode(im1_data, cv2.IMREAD_COLOR)\n",
    "#Convert to HSV for creating a mask\n",
    "    image_hsv = cv2.cvtColor(image_bgr2, cv2.COLOR_BGR2HSV)\n",
    "#Convert to grayscale that will actually be used for training, instead of color image \n",
    "    image_gray = cv2.cvtColor(image_bgr2, cv2.COLOR_BGR2GRAY)\n",
    "#Create a mask that detects the red rectangular tags present in each image\n",
    "    mask = cv2.inRange(image_hsv, (0,255,255), (0,255,255))\n",
    "#Get the coordinates of the red rectangle in the image, \n",
    "    #But take entire image if mask fails to detect the red rectangle\n",
    "    if len(np.where(mask != 0)[0]) != 0:\n",
    "        y1 = min(np.where(mask != 0)[0])\n",
    "        y2 = max(np.where(mask != 0)[0])\n",
    "    else:\n",
    "        y1 = 0                                     \n",
    "        y2 = len(mask)\n",
    "    if len(np.where(mask != 0)[1]) != 0:\n",
    "        x1 = min(np.where(mask != 0)[1])\n",
    "        x2 = max(np.where(mask != 0)[1])\n",
    "    else:\n",
    "        x1 = 0\n",
    "        x2 = len(mask[0])\n",
    "#Crop the grayscle image along those coordinates\n",
    "    image_cropped = image_gray[y1:y2, x1:x2]\n",
    "    if image_cropped.size ==0:\n",
    "        print(fil)\n",
    "        return image_cropped\n",
    "    else:\n",
    "    #Resize the image to 100x100 pixels size\n",
    "        image_128x128 = cv2.resize(image_cropped, (128, 128))\n",
    "#Save image as in form of array of 10000x1\n",
    "        image_arr = image_128x128.flatten()\n",
    "    return image_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b231635a-39e3-4315-aa54-414fa115fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b92040-a654-445d-8dd6-fd8be376f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a0893f-832e-412a-b482-5b3237912d84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in tqdm(df2['Filepath'].tolist()[:]):\n",
    "    image_list.append(image_processing(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d9637b-90eb-4cc3-bfb4-908142ab6b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc32b557-309a-4756-a356-e8092a3f11e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('processed_128x128_image.npy',X/255,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa891fc1-1540-40c6-9ec6-285afe38dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_array = np.load('processed_128x128_image.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c658ef2-353c-4370-b735-b735c0a6e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove non 16384 dimension out of the numpy array\n",
    "X =[]\n",
    "exclude =[]\n",
    "for i in range(len(pic_array)):\n",
    "    if pic_array[i].shape == (16384,):\n",
    "        X.append(pic_array[i])\n",
    "    else:\n",
    "        exclude.append(i)\n",
    "X =np.array(X)\n",
    "#also remove from the dataframe\n",
    "df2.drop(df2.index[exclude],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2aaf7f-3a24-44b6-aec3-cf26690acdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "for i in np.random.randint(0, len(pic_array), 2):\n",
    "    plt.figure()\n",
    "    plt.imshow(pic_array[i].reshape(128, 128), cmap='gray'), plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096730ae-c699-4149-86da-1e5e21d30a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #for numerical computations\n",
    "import pandas as pd #for dataframe operations\n",
    "\n",
    "from matplotlib import pyplot as plt #for viewing images and plots\n",
    "%matplotlib inline \n",
    "#So that Matplotlib plots don't open in separate windows outside the notebook\n",
    "\n",
    "import urllib #For fetching data from Web URLs\n",
    "\n",
    "import cv2   #For image processing\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder    #For encoding categorical variables\n",
    "from sklearn.model_selection import train_test_split #For splitting of data\n",
    "#All tensorflow utilities for creating, training and working with a CNN\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e7f43-1cc9-4749-88dc-6594b6620d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(df2.qplume.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4115b9-618f-4596-a7db-43f429a66f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bbf5f0-6e35-4a27-9912-85007ba33c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segregation of a test set for testing on the trained model\n",
    "\n",
    "#X_test = X[2095:,]\n",
    "#Y_test2 = Y[2095:,]\n",
    "\n",
    "#Seperation of a validation set from the remaing training set (required for validation while training)\n",
    "\n",
    "#X_train, X_val, Y_train, Y_val = train_test_split(X[:2094,], Y[:2094,], test_size=0.15, random_state=13)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the train set into train and validation sets\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d0b43-973f-4207-8326-5bf4f568a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 128, 128\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4ef7ac-d545-46a9-8d97-1ee4a908f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c538546d-b76f-456d-8892-26fe22215096",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764694eb-fe2c-4205-bfe0-88cdaa2cf4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a Convolutional Neural Network Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu',\n",
    "                 input_shape = input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "#model.add(Dense(n_classes, activation='softmax'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "learning_rate = 0.001\n",
    "\n",
    "model.compile(loss = 'mse',\n",
    "              optimizer = Adam(learning_rate))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ad6479-e680-449d-973f-5b59b80a98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_at = \"model_regression.hdf5\"\n",
    "save_best2 = ModelCheckpoint (save_at, monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=False, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a8221f-43c0-4c31-94bc-7e1975480220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the CNN\n",
    "\n",
    "history = model.fit( X_train, Y_train, \n",
    "                    epochs = 15, batch_size = 100, \n",
    "                    callbacks=[save_best2], verbose=1, \n",
    "                   validation_data = (X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d177ab2-3f29-432f-9129-a374ad830e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(history.history['loss'], color='r')\n",
    "plt.plot(history.history['val_loss'], color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb868776-2346-4e82-9e27-487c47859c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.round(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c1a932-9215-47cd-80bb-5e072e9ea0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b21a6d-4e7d-477c-8e83-d3252b75549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "\n",
    "# Calculate the root mean squared error\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "print(\"Test R^2 Score: {:.5f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3cf946-5468-4ffd-a4d7-8a42d36b330d",
   "metadata": {},
   "source": [
    "# Try 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29916823-24e8-4324-a91b-8937e65b967d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unet(pretrained_weights = None, input_size = (128,128,1)):\n",
    "\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # 128\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    # 128 -> 64\n",
    "    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    # 64 -> 32\n",
    "    conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    # 32 -> 16\n",
    "    conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    # Center: 16 -> 8\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    # 8 -> 16\n",
    "    up6 = Conv2DTranspose(256, (2,2),strides=(2,2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(drop5)\n",
    "    up6 = BatchNormalization()(up6)\n",
    "    merge6 = concatenate([drop4,up6],axis=3)\n",
    "    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    \n",
    "    # 16 -> 32\n",
    "    up7 = Conv2DTranspose(128,(2,2),strides=(2,2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    merge7 = concatenate([conv3,up7],axis=3)\n",
    "    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    \n",
    "    # 32 -> 64\n",
    "    up8 = Conv2DTranspose(64,(2,2),strides=(2,2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    up8 = BatchNormalization()(up8)\n",
    "    merge8 = concatenate([conv2,up8],axis=3)\n",
    "    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    \n",
    "    # 64 -> 128\n",
    "    up9 = Conv2DTranspose(32,(2,2),strides=(2,2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    up9 = BatchNormalization()(up9)\n",
    "    merge9 = concatenate([conv1,up9],axis=3)\n",
    "    conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e55966-a39b-4225-a235-b90f3993384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_at2 = \"model_regression2.hdf5\"\n",
    "save_best2 = ModelCheckpoint (save_at, monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=False, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889a8bf7-6cbb-49a0-b477-05e8f3cbd1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping2 = EarlyStopping(monitor ='val_accuracy', patience = 5, verbose = 1)\n",
    "model_checkpoint2 = ModelCheckpoint(save_at2, monitor='val_accuracy', save_best_only = True, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa6a8cf-3cab-4a4d-9ef9-240542c0f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the CNN\n",
    "\n",
    "history = model.fit( X_train, Y_train, \n",
    "                    epochs = 30, batch_size = 32, \n",
    "                    callbacks = [early_stopping2, model_checkpoint2], verbose=1, \n",
    "                   validation_data = (X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6244add-c6c4-48af-8cf4-55094df89776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
